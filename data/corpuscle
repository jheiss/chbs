#!/usr/bin/env ruby

# Be sure to run this script under 'bundle exec', otherwise it may attempt to
# update the corpus in your installed copy of the chbs gem.

require 'chbs'
require 'json'
require 'nokogiri'
require 'set'

def main
  offensefile = File.expand_path('offensive.json', File.dirname(__FILE__))
  @offensive = JSON.parse(File.read(offensefile))
  @enable = Set.new
  File.foreach('enable1.txt') { |enword| @enable << enword.chomp }
  
  if !ARGV[0] || ARGV[0] == 'tv-and-movies'
    tv_and_movies
  end
  if !ARGV[0] || ARGV[0] == 'gutenberg'
    gutenberg
  end
end

def tv_and_movies
  corpus = {}
  
  datadir = File.expand_path('../wiktionary/tv-and-movies/', __FILE__)
  Dir.foreach(datadir) do |file|
    next if file == '.' || file == '..'
    doc = Nokogiri::HTML(File.open(File.join(datadir, file)))
    first = true
    doc.xpath("/html/body/div[@id='content']/div[@id='bodyContent']/div[@class='mw-content-ltr']/table/tr").each do |tr|
      # Skip the header line
      if first
        first = false
        if tr.at_xpath('td/b')
          next
        end
      end
      
      # <tr>
      # <td>1</td>
      # <td><a href="/wiki/you" title="you">you</a></td>
      # <td>1222421</td>
      # </tr>
      # <tr>
      td = tr.xpath('td').to_a
      # Ignore some cruft in a few files
      next if td[0].content.include?('-----')
      rank = td[0].content.to_i
      word = td[1].at_xpath('a').content
      count = td[2].content.to_i
      next if reject_word?(word)
      
      corpus[word] = {rank: rank, length: word.length}
    end
  end
  
  corpusfile = File.join(Chbs::CORPORA_DIRECTORY, 'tv-and-movies.json')
  File.open(corpusfile, 'w') do |file|
    file.write corpus.to_json
  end
  report_on_corpus_generation(corpus, corpusfile)
end

def gutenberg
  corpus = {}
  
  rank = 0
  datadir = File.expand_path('../wiktionary/gutenberg/', __FILE__)
  Dir.foreach(datadir) do |file|
    next if file == '.' || file == '..'
    doc = Nokogiri::HTML(File.open(File.join(datadir, file)))
    doc.xpath("/html/body/div[@id='content']/div[@id='bodyContent']/div[@class='mw-content-ltr']/p/a").each do |a|
      rank += 1
      word = a.content
      next if reject_word?(word)
      corpus[word] = {rank: rank, length: word.length}
    end
  end
  
  corpusfile = File.join(Chbs::CORPORA_DIRECTORY, 'gutenberg.json')
  File.open(corpusfile, 'w') do |file|
    file.write corpus.to_json
  end
  report_on_corpus_generation(corpus, corpusfile)
end

def reject_word?(word)
  # Skip contractions
  return true if word.include?("'")
  # Skip proper names and capitalized words
  return true if word =~ /^[A-Z]/
  # Skip non-ASCII words
  return true if word =~ /[^a-z]/
  # Skip compound words
  return true if word.include?('-')
  # Skip offensive words
  return true if @offensive['exact'].include?(word)
  return true if @offensive['substring'].any? { |o| word.include?(o) }
  # Skip non-dictionary names
  # This eliminates a lot of the people and place names, as well as gibberish
  # words, from the tv-and-movies corpus.  I'd actually kinda like to keep the
  # place names eventually.
  return true if !@enable.include?(word)
  
  false
end

def report_on_corpus_generation(corpus, corpusfile)
  puts "Wrote corpus with #{corpus.length} words to #{corpusfile}"
end

main
